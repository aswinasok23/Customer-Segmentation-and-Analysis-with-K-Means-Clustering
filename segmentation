import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

# Step 1: Load the dataset
url = 'Mall_Customers.csv'
df = pd.read_csv(url)

# Step 2: Explore the dataset
print(df.head())
print(df.describe())
print(df.info())

# Step 3: Data Preprocessing
df = df.dropna()
features = df[['Annual Income (k$)', 'Spending Score (1-100)']]
scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)

# Step 4: Determine the Optimal Number of Clusters
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=42)
    kmeans.fit(features_scaled)
    wcss.append(kmeans.inertia_)

plt.figure(figsize=(10, 6))
plt.plot(range(1, 11), wcss, marker='o', linestyle='--')
plt.title('Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

# Step 5: Apply K-Means Clustering
kmeans = KMeans(n_clusters=5, init='k-means++', max_iter=300, n_init=10, random_state=42)
clusters = kmeans.fit_predict(features_scaled)
df['Cluster'] = clusters

# Step 6: Visualize the Clusters
pca = PCA(n_components=2)
features_pca = pca.fit_transform(features_scaled)

plt.figure(figsize=(10, 6))
sns.scatterplot(x=features_pca[:, 0], y=features_pca[:, 1], hue=df['Cluster'], palette='viridis', s=100, alpha=0.7)
plt.title('Customer Segments')
plt.xlabel('PCA 1')
plt.ylabel('PCA 2')
plt.show()

# Step 7: Analyze the Segments
for i in range(5):  # Assuming 5 clusters
    print(f"\nCluster {i} Statistics:")
    print(df[df['Cluster'] == i].describe())

# Step 8: Save the Model and Results (Optional)
joblib.dump(kmeans, 'kmeans_customer_segmentation.pkl')
df.to_csv('segmented_customers.csv', index=False)
